# AI_Chat_Processing_Agentic

Agent-based AI pipeline для обработки документов и чатов.
Проект объединяет конвертацию `.docx` в структурированные JSON-чаты и их последующую обработку через LLM
с использованием **function calling** и строгой валидации данных (Pydantic).

Это логическое развитие предыдущих проектов (`Practice`, `UnifiedRequest`) и переход
к **агентной архитектуре**.

---

## Идея проекта

Проект реализует AI-агента, который способен:

1. Конвертировать `.docx` файлы в JSON-чаты
2. Обрабатывать эти чаты через LLM:
   - извлекать описание проблемы
   - ключевые слова
   - пошаговое решение
3. Управлять всем процессом **через один агентный цикл**
   с использованием function calling

Агент сам выбирает, **какое действие выполнить**, на основе описанных функций и инструкций.

---

## Основной сценарий (agent flow)

1. Запуск `run.py`
2. Агент:
   - загружает инструкции и описание функций из JSON
   - формирует prompt для LLM
3. LLM возвращает:
   - либо финальный JSON-ответ
   - либо `function_call`
4. Агент вызывает соответствующую локальную функцию:
   - `process_docxs_to_json`
   - `chats_process`
   - `convert_and_process_dir`
5. Результаты сохраняются в выходные директории

---

## Архитектура проекта

### Точка входа
- `run.py` - запуск агентного цикла

### Основные модули

#### `solution/config/`
- `config.py` - пути, загрузка `.env`, инициализация AI API
- `functions_instructions.json` - инструкции для function calling
- `task_instructions.json` - инструкции для обработки чатов
- `functions_instructions_old.json` - предыдущая версия инструкций

#### `solution/docx_converter/`
Пайплайн конвертации `.docx → JSON`:
- `cleaner.py` - очистка текста
- `pipeline_docx_to_json.py` - последовательность шагов
- `docx_processing.py` - обработка файла или директории
- `models.py` - Pydantic-модели

#### `solution/chat_handler/`
Обработка JSON-чатов через LLM:
- `chat_processing.py` - обработка одного файла или директории
- `models.py` - Pydantic-модели запросов и ответов

#### `solution/json_loaders/`
Загрузка и валидация инструкций:
- `json_data_loader.py`
- `task_loader.py`
- `my_utils.py`
- `models.py`

#### `solution/convert_and_process/`
- `convert_and_process_dir.py` - объединение конвертации `.docx` и AI-обработки

---

## Используемые подходы

- Agent-based architecture
- Function calling (LLM управляет вызовами функций)
- Единая структура запросов
- JSON-only ответы от LLM
- Строгая валидация через **Pydantic v2**
- Явное разделение ответственности между слоями

---

## Установка и запуск

```bash
pip install -r requirements.txt
python run.py
```

Все пути к входным данным, директориям обработки и файлам инструкций
задаются в `solution/config/config.py`

## Примечания
Если LLM возвращает некорректный JSON, выводится сырой ответ
Проект рассчитан на пакетную обработку файлов и директорий
Токены и ключи API выносятся в .env
Архитектура готова к расширению под более сложных агентов
Хотя это решение есть не совсем агент, скорее agentic-application
